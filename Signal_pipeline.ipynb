{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NoranMorad7/BCI-Assistive-Motion/blob/main/Signal_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8Yw6fXmP0v-",
        "outputId": "3dcdb5ea-695f-4df7-9b06-b9e4a3c1dee3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base_path = '/content/drive/MyDrive/Colab Notebooks/files'\n",
        "\n",
        "# List files\n",
        "files = os.listdir(base_path)\n",
        "print(files)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_UifmzzSCya",
        "outputId": "198d968e-bd8c-4a4f-d526-a08c14777547"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['64_channel_sharbrough.pdf', 'ANNOTATORS', '64_channel_sharbrough-old.png', 'RECORDS', 'SHA256SUMS.txt', '64_channel_sharbrough.png', 'wfdbcal', 'S104', 'S107', 'S109', 'S106', 'S108', 'S101', 'S105', 'S102', 'S103', 'S100', 'S096', 'S090', 'S098', 'S097', 'S095', 'S094', 'S093', 'S099', 'S091', 'S092', 'S083', 'S080', 'S085', 'S086', 'S081', 'S082', 'S088', 'S089', 'S087', 'S084', 'S078', 'S075', 'S074', 'S070', 'S071', 'S072', 'S076', 'S079', 'S077', 'S073', 'S065', 'S066', 'S060', 'S068', 'S067', 'S069', 'S063', 'S061', 'S064', 'S062', 'S051', 'S055', 'S059', 'S057', 'S052', 'S050', 'S053', 'S058', 'S056', 'S054', 'S048', 'S043', 'S044', 'S045', 'S047', 'S040', 'S046', 'S049', 'S042', 'S041', 'S036', 'S037', 'S031', 'S039', 'S034', 'S030', 'S033', 'S032', 'S035', 'S038', 'S025', 'S027', 'S021', 'S023', 'S026', 'S029', 'S020', 'S028', 'S024', 'S022', 'S013', 'S016', 'S010', 'S018', 'S017', 'S011', 'S014', 'S015', 'S019', 'S012', 'S004', 'S003', 'S006', 'S008', 'S007', 'S009', 'S002', 'S001', 'S005']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mne\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import mne\n",
        "from scipy import signal\n",
        "from scipy.fft import fft\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n"
      ],
      "metadata": {
        "id": "vN-tnLEvDapA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64cf4294-c07f-41ba-a996-7125fb6f8ac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.11/dist-packages (1.9.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.11/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from mne) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mne) (24.2)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from mne) (1.15.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (4.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (2.32.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.6.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import mne\n",
        "\n",
        "base_path = '/content/drive/MyDrive/Colab Notebooks/files'\n",
        "target_len = 1600\n",
        "# Create 3 lists for eeg signals, frequances, and labels \"rest$ task\"\n",
        "eeg_trials = []\n",
        "labels = []\n",
        "fs_list = []\n",
        "\n",
        "# Select folders that start with \"S\" and print first 90 files\n",
        "subject_folders = [f for f in sorted(os.listdir(base_path)) if f.startswith('S') and os.path.isdir(os.path.join(base_path, f))]\n",
        "print(\"âœ… Found subject folders:\", subject_folders[:90])\n",
        "\n",
        "# Collect .EDF files for each folder\n",
        "for subj in subject_folders[:90]:\n",
        "    subj_path = os.path.join(base_path, subj)\n",
        "    edf_files = [f for f in os.listdir(subj_path) if f.endswith('.edf')]\n",
        "\n",
        "    print(f\"\\nðŸ“‚ Reading from {subj}: {len(edf_files)} EDF files\")\n",
        "\n",
        "# Identify recording num to know Task or Rest\n",
        "    for fname in edf_files:\n",
        "        edf_path = os.path.join(subj_path, fname)\n",
        "\n",
        "        try:\n",
        "            rec_id = fname.split('R')[-1].split('.')[0]\n",
        "            rec_num = int(rec_id)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "\n",
        "        if rec_num in [1, 2]:\n",
        "            label = 0  # rest\n",
        "        elif 3 <= rec_num <= 14:\n",
        "            label = 1  # task\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "# Read the files on only channel1\n",
        "        try:\n",
        "            raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n",
        "            sig = raw.get_data()[0]\n",
        "            fs = raw.info['sfreq']\n",
        "\n",
        "# To ensure all signals have the same length 1600\n",
        "            if len(sig) >= target_len:\n",
        "                sig_fixed = sig[:target_len]\n",
        "            else:\n",
        "                sig_fixed = np.pad(sig, (0, target_len - len(sig)), mode='constant')\n",
        "\n",
        "            eeg_trials.append(sig_fixed)\n",
        "            fs_list.append(fs)\n",
        "            labels.append(label)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error reading {fname}: {e}\")\n",
        "\n",
        "print(\"\\nðŸ§  Trials:\", len(eeg_trials), \"| fs_list:\", len(fs_list), \"| Labels:\", len(labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asJa1LB2QIGF",
        "outputId": "891555f5-fcee-4ac6-c9e0-05e7538c8a3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Found subject folders: ['S001', 'S002', 'S003', 'S004', 'S005', 'S006', 'S007', 'S008', 'S009', 'S010', 'S011', 'S012', 'S013', 'S014', 'S015', 'S016', 'S017', 'S018', 'S019', 'S020', 'S021', 'S022', 'S023', 'S024', 'S025', 'S026', 'S027', 'S028', 'S029', 'S030', 'S031', 'S032', 'S033', 'S034', 'S035', 'S036', 'S037', 'S038', 'S039', 'S040', 'S041', 'S042', 'S043', 'S044', 'S045', 'S046', 'S047', 'S048', 'S049', 'S050', 'S051', 'S052', 'S053', 'S054', 'S055', 'S056', 'S057', 'S058', 'S059', 'S060', 'S061', 'S062', 'S063', 'S064', 'S065', 'S066', 'S067', 'S068', 'S069', 'S070', 'S071', 'S072', 'S073', 'S074', 'S075', 'S076', 'S077', 'S078', 'S079', 'S080', 'S081', 'S082', 'S083', 'S084', 'S085', 'S086', 'S087', 'S088', 'S089', 'S090']\n",
            "\n",
            "ðŸ“‚ Reading from S001: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S002: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S003: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S004: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S005: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S006: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S007: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S008: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S009: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S010: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S011: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S012: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S013: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S014: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S015: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S016: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S017: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S018: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S019: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S020: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S021: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S022: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S023: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S024: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S025: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S026: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S027: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S028: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S029: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S030: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S031: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S032: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S033: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S034: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S035: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S036: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S037: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S038: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S039: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S040: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S041: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S042: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S043: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S044: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S045: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S046: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S047: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S048: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S049: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S050: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S051: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S052: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S053: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S054: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S055: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S056: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S057: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S058: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S059: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S060: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S061: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S062: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S063: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S064: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S065: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S066: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S067: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S068: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S069: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S070: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S071: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S072: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S073: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S074: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S075: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S076: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S077: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S078: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S079: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S080: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S081: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S082: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S083: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S084: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S085: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S086: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S087: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S088: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S089: 14 EDF files\n",
            "\n",
            "ðŸ“‚ Reading from S090: 14 EDF files\n",
            "\n",
            "ðŸ§  Trials: 1260 | fs_list: 1260 | Labels: 1260\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To filter noise and remove useless signals\n",
        "def bandpass_iir(data, fs, low=4, high=50, order=4):\n",
        "    nyq = fs / 2\n",
        "    b, a = signal.butter(order, [low / nyq, high / nyq], btype='band')\n",
        "    return signal.filtfilt(b, a, data)\n",
        "\n",
        "# Calculate the power to know values of theta w alph, each one represent different activity in brain\n",
        "def compute_band_power(x, fs, band):\n",
        "    freqs = np.fft.fftfreq(len(x), 1/fs)\n",
        "    fftv = np.abs(fft(x))**2\n",
        "    mask = (freqs >= band[0]) & (freqs <= band[1])\n",
        "    return np.sum(fftv[mask])\n",
        "\n",
        "def extract_features(trials, fs_list):\n",
        "    bands = {'theta': (4, 7), 'alpha': (8, 12), 'beta': (13, 30), 'gamma': (30, 50)} # Each signal converted to values of these 4 parameters\n",
        "    feats = []\n",
        "    for i, sig in enumerate(trials):\n",
        "        fs = fs_list[i]\n",
        "        sig_f = bandpass_iir(sig, fs)\n",
        "        feat = [compute_band_power(sig_f, fs, b) for b in bands.values()]\n",
        "        feats.append(feat)\n",
        "    return np.array(feats)"
      ],
      "metadata": {
        "id": "J2E3OrJ1Dmt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = extract_features(eeg_trials, fs_list)\n",
        "print(\"âœ… Features shape:\", features.shape)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(features)\n",
        "y = np.array(labels).astype(int)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "clf = GradientBoostingClassifier(n_estimators=200, random_state=42)  # 200 Iterations\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nðŸŽ¯ Accuracy: {acc:.2f}\")\n",
        "\n",
        "print(\"\\nðŸ“Š Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nðŸ“ Classification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "7KRIF_8VDqby",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79a8a223-44f0-4354-9194-303711ccc72e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Features shape: (1260, 4)\n",
            "\n",
            "ðŸŽ¯ Accuracy: 0.85\n",
            "\n",
            "ðŸ“Š Confusion Matrix:\n",
            " [[  9  27]\n",
            " [ 10 206]]\n",
            "\n",
            "ðŸ“ Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.25      0.33        36\n",
            "           1       0.88      0.95      0.92       216\n",
            "\n",
            "    accuracy                           0.85       252\n",
            "   macro avg       0.68      0.60      0.62       252\n",
            "weighted avg       0.83      0.85      0.83       252\n",
            "\n"
          ]
        }
      ]
    }
  ]
}